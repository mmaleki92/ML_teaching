{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# MACHINE TRANSLATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:150%;\">The objective is to Explain How Seq 2 Seq and LSTMs are used for Machine Translations using an example dataset of converting a German sentence to its English counterpart.</p>\n",
    "\n",
    "<h1> What is Seq2Seq Modelling ?</h1>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size:150%;\">Sequence-to-sequence learning (Seq2Seq) is about training models to convert sequences from one domain (e.g. sentences in English) to sequences in another domain (e.g. the same sentences translated to German). Our aim is to translate given sentences from German language to English.</li>\n",
    "    <li style=\"font-size:150%;\">Sequence-to-Sequence (seq2seq) models are used for a variety of NLP tasks, such as text summarization, speech recognition, DNA sequence modeling, among others.</li>\n",
    "    <li style=\"font-size:150%;\">Here, both the input and output are sentences. In other words, these sentences are a sequence of words going in and out of a model. This is the basic idea of Sequence-to-Sequence modeling. The figure below tries to explain this method.</li>\n",
    "</ul>\n",
    "\n",
    "<center><img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/enc_dec_simple.png\"></center>\n",
    "\n",
    "<h2>  Here's how it works:</h2>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size:150%;\">Feed the embedding vectors for source sequences (German), to the encoder network, one word at a time.</li>\n",
    "    <li style=\"font-size:150%;\">Encode the input sentences into fixed dimension state vectors. At this step, we get the hidden and cell states from the encoder LSTM, and feed it to the decoder LSTM.</li>\n",
    "    <li style=\"font-size:150%;\">These states are regarded as initial states by decoder. Additionally, it also has the embedding vectors for target words (English).</li>\n",
    "    <li style=\"font-size:150%;\">Decode and output the translated sentence, one word at a time. In this step, the output of the decoder is sent to a softmax layer over the entire target vocabulary.</li>\n",
    "</ul>\n",
    "\n",
    "<h1> What is LSTM ?</h1>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size:150%;\">Long Short-Term Memory (LSTM) networks are a modified version of recurrent neural networks, which makes it easier to remember past data in memory. The vanishing gradient problem of RNN is resolved here. LSTM is well-suited to classify, process and predict time series given time lags of unknown duration. It trains the model by using back-propagation. In an LSTM network, three gates are present:</li>\n",
    "</ul>\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/700/1*MwU5yk8f9d6IcLybvGgNxA.jpeg\"></center>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size:150%;\"><b>Input gate —</b> discover which value from input should be used to modify the memory. Sigmoid function decides which values to let through 0,1. and tanh function gives weightage to the values which are passed deciding their level of importance ranging from-1 to 1.</li>\n",
    "    <center><img src=\"https://miro.medium.com/max/500/1*k1lxwjsxxn8O4BEiVlQNdg.png\"></center>\n",
    "    <li style=\"font-size:150%;\"><b>Forget gate —</b> discover what details to be discarded from the block. It is decided by the sigmoid function. it looks at the previous state(ht-1) and the content input(Xt) and outputs a number between 0(omit this)and 1(keep this)for each number in the cell state Ct−1.</li>\n",
    "    <center><img src=\"https://miro.medium.com/max/500/1*bQnecA5sy_eepNkL8I-95A.png\"></center>\n",
    "    <li style=\"font-size:150%;\"><b>Output gate —</b> the input and the memory of the block is used to decide the output. Sigmoid function decides which values to let through 0,1. and tanh function gives weightage to the values which are passed deciding their level of importance ranging from-1 to 1 and multiplied with output of Sigmoid.</li>\n",
    "    <center><img src=\"https://miro.medium.com/max/700/1*s8532P11PgGi2sZqikZ2kA.png\"></center>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:200%; background-color:skyblue; color:black; padding:15px; font-family:Garamond;\"><b>Let's start the Implementation</b></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:27:08.662677Z",
     "iopub.status.busy": "2025-05-28T05:27:08.662404Z",
     "iopub.status.idle": "2025-05-28T05:27:08.669104Z",
     "shell.execute_reply": "2025-05-28T05:27:08.668273Z",
     "shell.execute_reply.started": "2025-05-28T05:27:08.662653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Load the Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:27:10.227334Z",
     "iopub.status.busy": "2025-05-28T05:27:10.227053Z",
     "iopub.status.idle": "2025-05-28T05:27:10.231498Z",
     "shell.execute_reply": "2025-05-28T05:27:10.230517Z",
     "shell.execute_reply.started": "2025-05-28T05:27:10.227312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:27:11.773596Z",
     "iopub.status.busy": "2025-05-28T05:27:11.773311Z",
     "iopub.status.idle": "2025-05-28T05:27:11.777685Z",
     "shell.execute_reply": "2025-05-28T05:27:11.776861Z",
     "shell.execute_reply.started": "2025-05-28T05:27:11.773571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:27:27.844966Z",
     "iopub.status.busy": "2025-05-28T05:27:27.844626Z",
     "iopub.status.idle": "2025-05-28T05:27:30.526128Z",
     "shell.execute_reply": "2025-05-28T05:27:30.525383Z",
     "shell.execute_reply.started": "2025-05-28T05:27:27.844935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = read_text(\"../input/bilingual-sentence-pairs/deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:27:37.031458Z",
     "iopub.status.busy": "2025-05-28T05:27:37.030963Z",
     "iopub.status.idle": "2025-05-28T05:27:37.036978Z",
     "shell.execute_reply": "2025-05-28T05:27:37.035718Z",
     "shell.execute_reply.started": "2025-05-28T05:27:37.031411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">The actual data contains over 150,000 sentence-pairs. However, we will use only the first 50,000 sentence pairs to reduce the training time of the model. You can change this number as per your system’s computation power.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Text Cleaning / Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">We will get rid of the punctuation marks and then convert all the text to lower case.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:27:54.277914Z",
     "iopub.status.busy": "2025-05-28T05:27:54.277547Z",
     "iopub.status.idle": "2025-05-28T05:27:54.761376Z",
     "shell.execute_reply": "2025-05-28T05:27:54.760593Z",
     "shell.execute_reply.started": "2025-05-28T05:27:54.277880Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go', 'Geh',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
       "       ['Hi', 'Hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi', 'Grüß Gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ...,\n",
       "       ['Im giving up smoking', 'Ich höre mit dem Rauchen auf',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #256952 (minshirui) & #407184 (MUIRIEL)'],\n",
       "       ['Im glad I was nearby', 'Ich bin froh dass ich in der Nähe war',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2547219 (CK) & #3448316 (Pfirsichbaeumchen)'],\n",
       "       ['Im glad Tom has gone', 'Ich bin froh dass Tom weg ist',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2547217 (CK) & #5299642 (Pfirsichbaeumchen)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
    "\n",
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:14.742588Z",
     "iopub.status.busy": "2025-05-28T05:28:14.742262Z",
     "iopub.status.idle": "2025-05-28T05:28:14.957718Z",
     "shell.execute_reply": "2025-05-28T05:28:14.957059Z",
     "shell.execute_reply.started": "2025-05-28T05:28:14.742555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert text to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:16.439375Z",
     "iopub.status.busy": "2025-05-28T05:28:16.439045Z",
     "iopub.status.idle": "2025-05-28T05:28:17.007571Z",
     "shell.execute_reply": "2025-05-28T05:28:17.006763Z",
     "shell.execute_reply.started": "2025-05-28T05:28:16.439344Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/plotting/_matplotlib/tools.py:331: MatplotlibDeprecationWarning: \n",
      "The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n",
      "  if ax.is_first_col():\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "      deu_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">A Seq2Seq model requires that we convert both the input and the output sentences into integer sequences of fixed length.</li>\n",
    "    <li style=\"font-size:150%;\">Now, vectorize our text data by using Keras’s Tokenizer() class. It will turn our sentences into sequences of integers. We can then pad those sequences with zeros to make all the sequences of the same length.</li>\n",
    "    <li style=\"font-size:150%;\">Prepare tokenizers for both the German and English sentences</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:22.700117Z",
     "iopub.status.busy": "2025-05-28T05:28:22.699773Z",
     "iopub.status.idle": "2025-05-28T05:28:22.703864Z",
     "shell.execute_reply": "2025-05-28T05:28:22.703061Z",
     "shell.execute_reply.started": "2025-05-28T05:28:22.700088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:29.665927Z",
     "iopub.status.busy": "2025-05-28T05:28:29.665610Z",
     "iopub.status.idle": "2025-05-28T05:28:30.132046Z",
     "shell.execute_reply": "2025-05-28T05:28:30.131218Z",
     "shell.execute_reply.started": "2025-05-28T05:28:29.665900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6256\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:32.376666Z",
     "iopub.status.busy": "2025-05-28T05:28:32.376269Z",
     "iopub.status.idle": "2025-05-28T05:28:32.910109Z",
     "shell.execute_reply": "2025-05-28T05:28:32.909199Z",
     "shell.execute_reply.started": "2025-05-28T05:28:32.376630Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 10329\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">We tokenized the data — i.e., converted the text to numerical values. This allows the neural network to perform operations on the input data.</li>\n",
    "    <li style=\"font-size:150%;\">When we run the tokenizer, it creates a word index, which is then used to convert each sentence to a vector.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:34.648063Z",
     "iopub.status.busy": "2025-05-28T05:28:34.647725Z",
     "iopub.status.idle": "2025-05-28T05:28:34.651914Z",
     "shell.execute_reply": "2025-05-28T05:28:34.650989Z",
     "shell.execute_reply.started": "2025-05-28T05:28:34.648035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">When we feed our sequences of word IDs into the model, each sequence needs to be the same length. To achieve this, padding is added to any sequence that is shorter than the max length (i.e. shorter than the longest sentence).</li>\n",
    "</ul>\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/1728/0*6jZTOE0P7_i7N8pn.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:200%; background-color:skyblue; color:black; padding:15px; font-family:Garamond;\"><b>Model Building</b></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:150%;\">CODE REFERENCE: https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/</p>\n",
    "\n",
    "<p style=\"font-size:170%;\">First, let’s breakdown the architecture of an RNN at a high level. Referring to the diagram above, there are a few parts of the model we to be aware of:</p>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size:150%;\">Inputs. Input sequences are fed into the model with one word for every time step. Each word is encoded as a unique integer so that it maps to the German dataset vocabulary.</li>\n",
    "    <li style=\"font-size:150%;\">Embedding Layers. Embeddings are used to convert each word to a vector. The size of the vector depends on the complexity of the vocabulary.</li>\n",
    "    <li style=\"font-size:150%;\">LSTM Layer (Encoder). This is where the context from word vectors in previous time steps is applied to the current word vector.</li>\n",
    "    <li style=\"font-size:150%;\">Dense Layers (Decoder). These are typical fully connected layers used to decode the encoded input into the correct translation sequence.</li>\n",
    "    <li style=\"font-size:150%;\">he outputs are returned as a sequence of integers or one-hot encoded vectors which can then be mapped to the English dataset vocabulary.</li>\n",
    "</ul>\n",
    "    \n",
    "    \n",
    "<center><h1 style=\"font-size:150%;\">Model Architecture</h1></center>\n",
    "<center><img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/01/architecture.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:44.108312Z",
     "iopub.status.busy": "2025-05-28T05:28:44.108016Z",
     "iopub.status.idle": "2025-05-28T05:28:44.951099Z",
     "shell.execute_reply": "2025-05-28T05:28:44.950276Z",
     "shell.execute_reply.started": "2025-05-28T05:28:44.108289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test set\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">It’s time to encode the sentences. We will encode German sentences as the input sequences and English sentences as the target sequences. This has to be done for both the train and test datasets.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:47.869229Z",
     "iopub.status.busy": "2025-05-28T05:28:47.868935Z",
     "iopub.status.idle": "2025-05-28T05:28:49.235548Z",
     "shell.execute_reply": "2025-05-28T05:28:49.234656Z",
     "shell.execute_reply.started": "2025-05-28T05:28:47.869205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "\n",
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Define the Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:50.863619Z",
     "iopub.status.busy": "2025-05-28T05:28:50.863306Z",
     "iopub.status.idle": "2025-05-28T05:28:50.868306Z",
     "shell.execute_reply": "2025-05-28T05:28:50.867504Z",
     "shell.execute_reply.started": "2025-05-28T05:28:50.863586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:52.066356Z",
     "iopub.status.busy": "2025-05-28T05:28:52.066025Z",
     "iopub.status.idle": "2025-05-28T05:28:56.234558Z",
     "shell.execute_reply": "2025-05-28T05:28:56.233627Z",
     "shell.execute_reply.started": "2025-05-28T05:28:52.066326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:56.236141Z",
     "iopub.status.busy": "2025-05-28T05:28:56.235887Z",
     "iopub.status.idle": "2025-05-28T05:28:56.249024Z",
     "shell.execute_reply": "2025-05-28T05:28:56.248297Z",
     "shell.execute_reply.started": "2025-05-28T05:28:56.236117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">We are using the RMSprop optimizer in this model as it’s usually a good choice when working with recurrent neural networks.</li>\n",
    "    <li style=\"font-size:150%;\">Here I have used ‘sparse_categorical_crossentropy‘ as the loss function. This is because the function allows us to use the target sequence as is, instead of the one-hot encoded format. One-hot encoding the target sequences using such a huge vocabulary might consume our system’s entire memory.</li>\n",
    "               \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Fit the Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:150%;\">ModelCheckpoint() function to save the model with the lowest validation loss. I personally prefer this method over early stopping.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:28:56.548595Z",
     "iopub.status.busy": "2025-05-28T05:28:56.548305Z",
     "iopub.status.idle": "2025-05-28T05:36:24.889831Z",
     "shell.execute_reply": "2025-05-28T05:36:24.888895Z",
     "shell.execute_reply.started": "2025-05-28T05:28:56.548568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 14s 102ms/step - loss: 4.3393 - val_loss: 2.8775\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.87749, saving model to model.h1.24_jan_19\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 5s 76ms/step - loss: 2.7882 - val_loss: 2.7189\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.87749 to 2.71892, saving model to model.h1.24_jan_19\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 5s 77ms/step - loss: 2.6253 - val_loss: 2.5675\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.71892 to 2.56750, saving model to model.h1.24_jan_19\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 2.4270 - val_loss: 2.4511\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.56750 to 2.45109, saving model to model.h1.24_jan_19\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 2.2824 - val_loss: 2.3192\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.45109 to 2.31917, saving model to model.h1.24_jan_19\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 2.1467 - val_loss: 2.2240\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.31917 to 2.22398, saving model to model.h1.24_jan_19\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 2.0184 - val_loss: 2.0988\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.22398 to 2.09881, saving model to model.h1.24_jan_19\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 1.8925 - val_loss: 2.0341\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.09881 to 2.03412, saving model to model.h1.24_jan_19\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 1.7781 - val_loss: 1.9382\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.03412 to 1.93822, saving model to model.h1.24_jan_19\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 1.6713 - val_loss: 1.8864\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.93822 to 1.88644, saving model to model.h1.24_jan_19\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 1.5813 - val_loss: 1.8615\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.88644 to 1.86145, saving model to model.h1.24_jan_19\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 1.4839 - val_loss: 1.8021\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.86145 to 1.80212, saving model to model.h1.24_jan_19\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 1.3927 - val_loss: 1.7023\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.80212 to 1.70230, saving model to model.h1.24_jan_19\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 1.3052 - val_loss: 1.6550\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.70230 to 1.65499, saving model to model.h1.24_jan_19\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 1.2207 - val_loss: 1.6415\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.65499 to 1.64151, saving model to model.h1.24_jan_19\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 1.1465 - val_loss: 1.5742\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.64151 to 1.57423, saving model to model.h1.24_jan_19\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 1.0772 - val_loss: 1.5377\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.57423 to 1.53767, saving model to model.h1.24_jan_19\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 5s 87ms/step - loss: 1.0015 - val_loss: 1.5168\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.53767 to 1.51682, saving model to model.h1.24_jan_19\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - 6s 86ms/step - loss: 0.9291 - val_loss: 1.4806\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.51682 to 1.48063, saving model to model.h1.24_jan_19\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.8663 - val_loss: 1.4515\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.48063 to 1.45145, saving model to model.h1.24_jan_19\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.8068 - val_loss: 1.4157\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.45145 to 1.41574, saving model to model.h1.24_jan_19\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.7493 - val_loss: 1.4168\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.41574\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - 5s 86ms/step - loss: 0.6915 - val_loss: 1.3770\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.41574 to 1.37701, saving model to model.h1.24_jan_19\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.6393 - val_loss: 1.3734\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.37701 to 1.37344, saving model to model.h1.24_jan_19\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - 5s 84ms/step - loss: 0.5882 - val_loss: 1.3462\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.37344 to 1.34621, saving model to model.h1.24_jan_19\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - 5s 85ms/step - loss: 0.5411 - val_loss: 1.3594\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.34621\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.4999 - val_loss: 1.3617\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.34621\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.4585 - val_loss: 1.3527\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.34621\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - 6s 88ms/step - loss: 0.4189 - val_loss: 1.3127\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.34621 to 1.31272, saving model to model.h1.24_jan_19\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - 5s 83ms/step - loss: 0.3828 - val_loss: 1.3174\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.31272\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.24_jan_19'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
    "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:36:24.892407Z",
     "iopub.status.busy": "2025-05-28T05:36:24.892002Z",
     "iopub.status.idle": "2025-05-28T05:36:25.083801Z",
     "shell.execute_reply": "2025-05-28T05:36:25.082828Z",
     "shell.execute_reply.started": "2025-05-28T05:36:24.892367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Prediction on unseen data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:50:26.658618Z",
     "iopub.status.busy": "2025-05-28T05:50:26.658252Z",
     "iopub.status.idle": "2025-05-28T05:50:38.807196Z",
     "shell.execute_reply": "2025-05-28T05:50:38.806238Z",
     "shell.execute_reply.started": "2025-05-28T05:50:26.658581Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h1.24_jan_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:50:43.559548Z",
     "iopub.status.busy": "2025-05-28T05:50:43.559240Z",
     "iopub.status.idle": "2025-05-28T05:50:43.563893Z",
     "shell.execute_reply": "2025-05-28T05:50:43.562834Z",
     "shell.execute_reply.started": "2025-05-28T05:50:43.559520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:50:45.578171Z",
     "iopub.status.busy": "2025-05-28T05:50:45.577845Z",
     "iopub.status.idle": "2025-05-28T05:52:28.427121Z",
     "shell.execute_reply": "2025-05-28T05:52:28.426379Z",
     "shell.execute_reply.started": "2025-05-28T05:50:45.578142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:52:28.428531Z",
     "iopub.status.busy": "2025-05-28T05:52:28.428291Z",
     "iopub.status.idle": "2025-05-28T05:52:28.440586Z",
     "shell.execute_reply": "2025-05-28T05:52:28.439772Z",
     "shell.execute_reply.started": "2025-05-28T05:52:28.428510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T05:52:28.442465Z",
     "iopub.status.busy": "2025-05-28T05:52:28.442111Z",
     "iopub.status.idle": "2025-05-28T05:52:28.459233Z",
     "shell.execute_reply": "2025-05-28T05:52:28.458427Z",
     "shell.execute_reply.started": "2025-05-28T05:52:28.442428Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i know that already</td>\n",
       "      <td>i already know that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whos she</td>\n",
       "      <td>who is she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do you have it</td>\n",
       "      <td>did you bring it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use your feet</td>\n",
       "      <td>get your  kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that was the trouble</td>\n",
       "      <td>was the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he took off his coat</td>\n",
       "      <td>he put his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tom went sightseeing</td>\n",
       "      <td>tom fought the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i tried on the shoes</td>\n",
       "      <td>i left my advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>open those doors</td>\n",
       "      <td>open the door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ive got to help tom</td>\n",
       "      <td>i have to help tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>its my money</td>\n",
       "      <td>its is money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is it time</td>\n",
       "      <td>is it time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i cant watch</td>\n",
       "      <td>i cant hear at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>he wants more</td>\n",
       "      <td>he wants an salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who did you see</td>\n",
       "      <td>who did you see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  actual                predicted\n",
       "0    i know that already  i already know that    \n",
       "1               whos she          who is she     \n",
       "2         do you have it     did you bring it    \n",
       "3          use your feet       get your  kids    \n",
       "4   that was the trouble            was the      \n",
       "5   he took off his coat          he put his     \n",
       "6   tom went sightseeing      tom fought the     \n",
       "7   i tried on the shoes     i left my advice    \n",
       "8       open those doors       open the door     \n",
       "9    ive got to help tom    i have to help tom   \n",
       "10          its my money        its is money     \n",
       "11            is it time          is it time     \n",
       "12          i cant watch       i cant hear at    \n",
       "13         he wants more    he wants an salad    \n",
       "14       who did you see      who did you see    "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 15 rows randomly\n",
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> CONCLUSION</h1></center>\n",
    "<br>\n",
    "\n",
    "<ul>\n",
    "    <li style=\"font-size:150%;\">Our Seq2Seq model does a decent job. But there are several instances where it misses out on understanding the key words.</li>\n",
    "    <li style=\"font-size:150%;\">These are the challenges you will face on a regular basis in NLP. But these aren’t immovable obstacles. We can mitigate such challenges by using more training data and building a better (or more complex) model.</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1118439,
     "sourceId": 1878727,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30096,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
