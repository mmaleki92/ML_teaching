{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Requirements"
      ],
      "metadata": {
        "id": "2NgY1Z2URlau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "Baf8ufnaRC9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test split"
      ],
      "metadata": {
        "id": "OCJmC4wvksTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X is your features and y is your labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "GUPME-4cRSoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold"
      ],
      "metadata": {
        "id": "_slaagZbRiBd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDhOgXhzQ3oQ",
        "outputId": "01f13fcd-57dd-4aff-c702-9f1144607efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.9666666666666667\n",
            "0.9333333333333333\n",
            "0.9333333333333333\n",
            "0.9333333333333333\n",
            "Average Accuracy: 0.9533333333333335\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load a sample dataset for demonstration (Iris dataset)\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Number of folds\n",
        "k = 5\n",
        "\n",
        "# Create KFold object\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy for each fold\n",
        "accuracies = []\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split data into training and test sets\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Create and train the model\n",
        "    model = DecisionTreeClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions and calculate accuracy\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    accuracies.append(accuracy)\n",
        "    print(accuracy)\n",
        "# Calculate average accuracy across all folds\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f\"Average Accuracy: {average_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2cLjhTXQ-tc",
        "outputId": "fda8a0a4-fdf8-4f23-a87a-5c90f0c4e204"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KFold(n_splits=5, random_state=42, shuffle=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "J4MoUzNQobLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binary Classification\n"
      ],
      "metadata": {
        "id": "QJZCoRjEp72Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Binary Classification Accuracy:\", accuracy_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDih4bIEoa-F",
        "outputId": "0f65612a-00fb-4a3b-e452-5acff467f0c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Classification Accuracy: 0.9649122807017544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiclass Classification"
      ],
      "metadata": {
        "id": "Lohn27CAqA9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForest model\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Multiclass Classification Accuracy:\", accuracy_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2i65VamqDx5",
        "outputId": "d4cb49a1-ac2a-4cf6-90b1-381895338cd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Classification Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilabel Classification"
      ],
      "metadata": {
        "id": "tgXmG98rqGSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_multilabel_classification(n_samples=1000, n_features=20, n_classes=3, n_labels=2, random_state=42)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a MultiOutputClassifier with DecisionTreeClassifier\n",
        "model = MultiOutputClassifier(DecisionTreeClassifier())\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Multilabel Classification Accuracy:\", accuracy_score(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICIEUj5MqERe",
        "outputId": "0e40b57d-ea65-4ccd-a755-dfba3ee02c0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multilabel Classification Accuracy: 0.405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiclass-Multilabel Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "ns-pUmDzqv6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate a synthetic multilabel dataset\n",
        "X, y = make_multilabel_classification(n_samples=1000, n_features=20, n_classes=5, n_labels=3, random_state=42)\n",
        "\n",
        "# Each label can belong to multiple classes, hence multiclass-multilabel\n",
        "# Here, 'y' will be a 2D array where each row has multiple labels, and each label can have multiple classes.\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Use MultiOutputClassifier with RandomForestClassifier\n",
        "model = MultiOutputClassifier(RandomForestClassifier(n_estimators=100))\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model - Using accuracy here for simplicity, but in real scenarios, consider more appropriate metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Multiclass-Multilabel Classification Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvoSnsHnqH2_",
        "outputId": "fff6b9d8-fb33-49d8-c849-870d92649e5c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass-Multilabel Classification Accuracy: 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imbalanced Classification"
      ],
      "metadata": {
        "id": "x_aCMzrur-JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Create an imbalanced dataset\n",
        "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0, n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=42)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to generate synthetic samples for balancing\n",
        "smote = SMOTE()\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train a RandomForest model on the balanced dataset\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "predictions = model.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNiRPTY_qvOv",
        "outputId": "9a9aa5f6-f428-488c-a68a-5bc10450ac26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00       187\n",
            "\n",
            "    accuracy                           1.00       200\n",
            "   macro avg       1.00      1.00      1.00       200\n",
            "weighted avg       1.00      1.00      1.00       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hierarchical Classification Example\n"
      ],
      "metadata": {
        "id": "NBDPD3jEr7Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Function to generate synthetic data\n",
        "def generate_data():\n",
        "    # Level 1 data (Animal vs Plant)\n",
        "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n",
        "    # Level 2 data (Mammal vs Bird), only for 'Animal' class (assumed to be labeled as '1')\n",
        "    X_sub, y_sub = make_classification(n_samples=np.sum(y), n_features=10, n_informative=5, n_classes=2, random_state=42)\n",
        "    return X, y, X_sub, y_sub\n",
        "\n",
        "# Generate synthetic dataset\n",
        "X, y, X_sub, y_sub = generate_data()\n",
        "\n",
        "# Split Level 1 data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Level 1 classifier (Animal vs Plant)\n",
        "model_level_1 = RandomForestClassifier()\n",
        "model_level_1.fit(X_train, y_train)\n",
        "\n",
        "# Predict Level 1 on test data\n",
        "predictions_level_1 = model_level_1.predict(X_test)\n",
        "\n",
        "# Prepare Level 2 data (only for 'Animal' class)\n",
        "X_sub_train, X_sub_test, y_sub_train, y_sub_test = train_test_split(X_sub, y_sub, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Level 2 classifier (Mammal vs Bird)\n",
        "model_level_2 = RandomForestClassifier()\n",
        "model_level_2.fit(X_sub_train, y_sub_train)\n",
        "\n",
        "# Predict Level 2 for samples classified as 'Animal' in Level 1\n",
        "animal_indices = np.where(predictions_level_1 == 1)  # Assuming '1' is for 'Animal'\n",
        "predictions_level_2 = np.zeros_like(predictions_level_1)\n",
        "predictions_level_2[animal_indices] = model_level_2.predict(X_test[animal_indices])\n",
        "\n",
        "# predictions_level_1 contains 'Animal' vs 'Plant'\n",
        "# predictions_level_2 contains 'Mammal' vs 'Bird' for 'Animal' class and zeros for 'Plant'\n",
        "\n",
        "# Note: In a real dataset, you would use actual hierarchical labels and potentially have more levels and categories.\n"
      ],
      "metadata": {
        "id": "C1Ll3PsbrVXR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# on-hot-encoding"
      ],
      "metadata": {
        "id": "z3G49Oui2uFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4RIUtx12trQ",
        "outputId": "049e55f0-05f7-4d10-94e1-d1832af9de78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {'color': ['blue', 'green', 'red', 'green']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Applying one-hot encoding\n",
        "encoded_df = pd.get_dummies(df, columns=['color'])\n",
        "\n",
        "print(encoded_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9OZLaIx2wGR",
        "outputId": "780b24a7-9590-413b-cf52-e768599e532b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   color_blue  color_green  color_red\n",
            "0           1            0          0\n",
            "1           0            1          0\n",
            "2           0            0          1\n",
            "3           0            1          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNNImputer"
      ],
      "metadata": {
        "id": "TzPEm_oD3ucT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Example data with missing values\n",
        "data = {\n",
        "    'Age': [25, np.nan, 27, 29, 30],\n",
        "    'Salary': [50000, 55000, np.nan, 60000, 65000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create KNNImputer instance\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "\n",
        "# Fit the imputer and transform the data\n",
        "df_imputed = imputer.fit_transform(df)\n",
        "\n",
        "# Convert the imputed data back to a DataFrame\n",
        "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n",
        "\n",
        "print(df_imputed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HRvhXsk21GJ",
        "outputId": "7114c579-5162-4513-e8da-26b3fa1926a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Age   Salary\n",
            "0  25.0  50000.0\n",
            "1  27.0  55000.0\n",
            "2  27.0  55000.0\n",
            "3  29.0  60000.0\n",
            "4  30.0  65000.0\n"
          ]
        }
      ]
    }
  ]
}